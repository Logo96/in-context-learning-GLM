out_dir: "gs://glm_weights/"

model:
  family: "gpt2"
  n_positions: 101
  n_dims: 10
  n_embd: 256
  n_layer: 12
  n_head: 8

training:
  task: "GLM"
  task_kwargs:
    function_type: "linear" #Overriden during deployment
  num_tasks: 10000
  num_training_examples: 10000
  data: "gaussian"
  batch_size: 64
  learning_rate: 0.001
  train_steps: 100
  save_every_steps: 500
  keep_every_steps: 2000
  resume_id: null
  curriculum:
    dims:
      start: 50
      end: 50
      inc: 0
      interval: 10000
    points:
      start: 50
      end: 50
      inc: 0
      interval: 10000

wandb:
  project: null
  entity: "logan-king"
  notes: "ICL GLM training"
  name: null
  log_every_steps: 100

test_run: false
