{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affc22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "ckpt_dir = \"/home/joseph_tennyson/182/in-context-learning-GLM/src/models/poisson-0.32\"\n",
    "n_tasks = 2500\n",
    "n_train = 40\n",
    "lr = 0.05\n",
    "max_steps = 100000\n",
    "tol = 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122deaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from tqdm import tqdm\n",
    "from torch.nn import PoissonNLLLoss\n",
    "from models import build_model  # Ensure this is in your working directory\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0c9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Data Sampling ===\n",
    "def sample_data(n_tasks, n_points, d, scale=0.32):\n",
    "    xs = torch.randn(n_tasks, n_points, d)\n",
    "    ws = scale * torch.randn(n_tasks, d, 1)\n",
    "    logits = xs @ ws\n",
    "    ys = torch.poisson(torch.exp(logits.clamp(max=4))).squeeze(-1)\n",
    "    return xs, ys, ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b48eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Config===\n",
    "config_path = os.path.join(ckpt_dir, \"config.yaml\")\n",
    "cfg = yaml.load(open(config_path), Loader=yaml.FullLoader)\n",
    "\n",
    "model_conf = SimpleNamespace(**cfg[\"model\"])\n",
    "\n",
    "# === Sample Data ===\n",
    "d = cfg[\"model\"][\"n_dims\"]\n",
    "scale = cfg[\"training\"][\"task_kwargs\"].get(\"scaling\", 1.0)\n",
    "xs_all, ys_all, _ = sample_data(n_tasks, n_train + 1, d, scale)\n",
    "xs_train, xs_test = xs_all[:, :-1].to(device), xs_all[:, -1:].to(device)\n",
    "ys_train, ys_test = ys_all[:, :-1].to(device), ys_all[:, -1:].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f52f35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Transformer Evaluation ===\n",
    "def evaluate_transformer(model, ckpt_file, xs_all, ys_all, xs_test, ys_test):\n",
    "    # model.eval()\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     out = model(xs_all, ys_all)\n",
    "    #     last_loglam = out[:, -1]\n",
    "    #     loss_fn = PoissonNLLLoss(log_input=True, full=True, reduction=\"mean\")\n",
    "    #     loss = loss_fn(last_loglam.unsqueeze(-1), ys_test)\n",
    "    # print(f\"{os.path.basename(ckpt_file)} | Transformer Poisson NLL: {loss.item():.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(xs_all, ys_all)  # shape: [n_tasks, seq_len]\n",
    "        loss_fn = PoissonNLLLoss(log_input=True, full=True, reduction=\"mean\")\n",
    "        loss = loss_fn(out, ys_all)\n",
    "    print(f\"{os.path.basename(ckpt_file)} | Transformer Poisson NLL (all points): {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6ca55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Oracle Gradient Descent Evaluation ===\n",
    "def evaluate_oracle(xs_train, ys_train, xs_test, ys_test, lr, max_steps, tol):\n",
    "    n_tasks, n_train, d = xs_train.shape\n",
    "    w_hat = torch.randn(n_tasks, d, 1, device=device, requires_grad=True)\n",
    "    opt = torch.optim.Adam([w_hat], lr=lr)\n",
    "    loss_fn = PoissonNLLLoss(log_input=False, full=True, reduction=\"mean\")\n",
    "    prev = float(\"inf\")\n",
    "\n",
    "    for step in tqdm(range(1, max_steps + 1), desc=\"Oracle GD\"):\n",
    "        logits = (xs_train @ w_hat).squeeze(-1).clamp(max=3)\n",
    "        pred = torch.exp(logits)\n",
    "        loss = loss_fn(pred, ys_train)\n",
    "        if abs(prev - loss.item()) < tol:\n",
    "            print(f\"Oracle converged at step {step} (Δloss={abs(prev-loss.item()):.2e})\")\n",
    "            break\n",
    "        prev = loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_test = (xs_test @ w_hat).squeeze(-1).clamp(max=3)\n",
    "        pred_test = torch.exp(logits_test)\n",
    "        final_loss = loss_fn(pred_test, ys_test)\n",
    "    print(f\"Oracle baseline Poisson NLL: {final_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1047f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Naive Baseline Evaluation ===\n",
    "def evaluate_naive(ys_train, ys_test):\n",
    "    naive_mean = ys_train.mean(dim=1, keepdim=True)\n",
    "    loss_fn = PoissonNLLLoss(log_input=False, full=True, reduction=\"mean\")\n",
    "    loss = loss_fn(naive_mean, ys_test)\n",
    "    print(f\"Naive Mean Baseline Poisson NLL: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22faf5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint model_1000.pt...\n",
      "Loading checkpoint model_2000.pt...\n",
      "Loading checkpoint model_3000.pt...\n",
      "Loading checkpoint model_4000.pt...\n",
      "Loading checkpoint model_5000.pt...\n",
      "Loading checkpoint model_6000.pt...\n",
      "Loading checkpoint model_7000.pt...\n",
      "Loading checkpoint state.pt...\n"
     ]
    }
   ],
   "source": [
    "pt_files = sorted(f for f in os.listdir(ckpt_dir) if f.endswith(\".pt\"))\n",
    "models = []\n",
    "\n",
    "for fname in pt_files:\n",
    "    ckpt_path = os.path.join(ckpt_dir, fname)\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    \n",
    "    model = build_model(model_conf).to(device)\n",
    "    \n",
    "    print(f\"Loading checkpoint {fname}...\")\n",
    "    model.load_state_dict(state['model_state_dict'] if 'model_state_dict' in state else state)\n",
    "    \n",
    "    models.append([model, fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "576d6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint model_1000.pt...\n",
      "model_1000.pt | Transformer Poisson NLL (all points): 2.2746\n",
      "Evaluating checkpoint model_2000.pt...\n",
      "model_2000.pt | Transformer Poisson NLL (all points): 1.9898\n",
      "Evaluating checkpoint model_3000.pt...\n",
      "model_3000.pt | Transformer Poisson NLL (all points): 1.8184\n",
      "Evaluating checkpoint model_4000.pt...\n",
      "model_4000.pt | Transformer Poisson NLL (all points): 1.7905\n",
      "Evaluating checkpoint model_5000.pt...\n",
      "model_5000.pt | Transformer Poisson NLL (all points): 1.7830\n",
      "Evaluating checkpoint model_6000.pt...\n",
      "model_6000.pt | Transformer Poisson NLL (all points): 1.7787\n",
      "Evaluating checkpoint model_7000.pt...\n",
      "model_7000.pt | Transformer Poisson NLL (all points): 1.7766\n",
      "Evaluating checkpoint state.pt...\n",
      "state.pt | Transformer Poisson NLL (all points): 1.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oracle GD:   0%|          | 385/100000 [00:00<01:55, 864.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle converged at step 386 (Δloss=0.00e+00)\n",
      "Oracle baseline Poisson NLL: 1.5592\n",
      "Naive Mean Baseline Poisson NLL: 2.3288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Run Transformer Models ===\n",
    "pt_files = sorted(f for f in os.listdir(ckpt_dir) if f.endswith(\".pt\"))\n",
    "for model, fname in models:\n",
    "    print(f\"Evaluating checkpoint {fname}...\")\n",
    "    evaluate_transformer(model, fname, xs_train, ys_train, xs_test, ys_test)\n",
    "\n",
    "# === Run Oracle & Naive ===\n",
    "evaluate_oracle(xs_train, ys_train, xs_test, ys_test, lr, max_steps, tol)\n",
    "evaluate_naive(ys_train, ys_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07553404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
