{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 1. Parameters & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "repo_id     = \"icl-182/poisson-1\"   \n",
        "ckpt_name   = \"state.pt\"              \n",
        "loss_type   = \"poisson\"            \n",
        "n_tasks     = 10000\n",
        "n_train     = 40                          \n",
        "lr          = 0.05\n",
        "max_steps   = 100000\n",
        "tol         = 1e-10\n",
        "# can be loaded in from config\n",
        "r_val = 5.0\n",
        "scale = 0.32\n",
        "\n",
        "# — Standard imports —\n",
        "import os, sys, yaml\n",
        "import torch\n",
        "from torch.nn import PoissonNLLLoss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download HF Repo & Load Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "758f1c72cc5344ceba9d24515e7883e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo downloaded to: /home/joseph_tennyson/.cache/huggingface/hub/models--icl-182--joint-training-r5.0/snapshots/60bf39e0e863e33e366b92aa47cbf6683ffbf3a9\n",
            "Config keys: dict_keys(['config', 'model', 'out_dir', 'test_run', 'training', 'wandb'])\n",
            "n_dims=10, scale=0.32, r=5.0\n"
          ]
        }
      ],
      "source": [
        "# if you don't already have huggingface_hub installed:\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "from types import SimpleNamespace\n",
        "\n",
        "# download into a local folder\n",
        "ckpt_dir = snapshot_download(repo_id, repo_type=\"model\")\n",
        "print(\"Repo downloaded to:\", ckpt_dir)\n",
        "\n",
        "sys.path.append(ckpt_dir)\n",
        "\n",
        "cfg = yaml.safe_load(open(os.path.join(ckpt_dir, \"config.yaml\")))\n",
        "print(\"Config keys:\", cfg.keys())\n",
        "\n",
        "model_conf = SimpleNamespace(**cfg[\"model\"])\n",
        "task_kwargs = cfg[\"training\"][\"task_kwargs\"]\n",
        "scale = task_kwargs.get(\"scaling\", 1.0)\n",
        "r_val = task_kwargs.get(\"r\", None) or r_val\n",
        "\n",
        "print(f\"n_dims={model_conf.n_dims}, scale={scale}, r={r_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sampling & Loss Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_data(n_tasks, n_points, d, ws=None, scale=1.0, loss_type=\"poisson\", r=None):\n",
        "    xs = torch.randn(n_tasks, n_points, d, device=device)\n",
        "    if ws is None:\n",
        "        ws = scale * torch.randn(n_tasks, d, 1, device=device)\n",
        "    logits = (xs @ ws).clamp(-4, 4)    # shape: [n_tasks, n_points, 1]\n",
        "    mu = torch.exp(logits)\n",
        "\n",
        "    if loss_type == \"poisson\":\n",
        "        ys = torch.poisson(mu).squeeze(-1)\n",
        "    elif loss_type in (\"nb\", \"neg_binomial\"):\n",
        "        r_t = torch.tensor(r, device=device, dtype=mu.dtype)\n",
        "        probs = r_t / (r_t + mu)\n",
        "        dist = torch.distributions.NegativeBinomial(total_count=r_t, probs=probs)\n",
        "        ys = dist.sample().squeeze(-1)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported loss_type: {loss_type}\")\n",
        "    return xs, ys, ws\n",
        "\n",
        "# registry for your model's NLL\n",
        "LOSS_REGISTRY = {}\n",
        "def register_loss(name):\n",
        "    def deco(fn):\n",
        "        LOSS_REGISTRY[name] = fn\n",
        "        return fn\n",
        "    return deco\n",
        "\n",
        "@register_loss(\"poisson\")\n",
        "def poisson_loss_fn(pred, targets, **kw):\n",
        "    return PoissonNLLLoss(log_input=True, full=True, reduction=\"none\")(pred, targets)\n",
        "\n",
        "@register_loss(\"nb\")\n",
        "def nb_loss_fn(preds, targets, r, **kw):\n",
        "    mu = torch.exp(preds)\n",
        "    r_t = torch.tensor(r, device=mu.device, dtype=mu.dtype)\n",
        "    probs = r_t / (r_t + mu)\n",
        "    dist = torch.distributions.NegativeBinomial(total_count=r_t, probs=probs)\n",
        "    return -dist.log_prob(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation Routines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# 4.1 Transformer evaluation\n",
        "def evaluate_transformer(model, xs_all, ys_all, loss_type=\"poisson\", r=None):\n",
        "    model.eval()\n",
        "    loss_fn = LOSS_REGISTRY[loss_type]\n",
        "    with torch.no_grad():\n",
        "        out = model(xs_all, ys_all)   \n",
        "        per_pos = loss_fn(out, ys_all, r=r).mean(dim=0)\n",
        "    return per_pos.cpu().tolist()\n",
        "\n",
        "# 4.2 Gradient‑descent oracle (re-fit per context length)\n",
        "def evaluate_oracle_gd(xs_all, ys_all, lr, max_steps, tol, scale=1.0, r=None, loss_type=\"poisson\"):\n",
        "    n_tasks, n_points, d = xs_all.shape\n",
        "    all_losses = []\n",
        "    loss_fn = LOSS_REGISTRY[loss_type]\n",
        "    for t in tqdm(range(1, n_points), desc=\"GD Oracle\"):\n",
        "        xs_tr = xs_all[:, :t, :]\n",
        "        ys_tr = ys_all[:, :t]\n",
        "        xs_te = xs_all[:, t:t+1, :]\n",
        "        ys_te = ys_all[:, t:t+1]\n",
        "\n",
        "        w_hat = torch.randn(n_tasks, d, 1, device=device, requires_grad=True)\n",
        "        opt = torch.optim.Adam([w_hat], lr=lr)\n",
        "        prev = float(\"inf\")\n",
        "        for step in range(max_steps):\n",
        "            logits = (xs_tr @ w_hat).squeeze(-1).clamp(-4,4)\n",
        "            loss = loss_fn(logits, ys_tr, r=r).mean()\n",
        "            loss = loss + (0.5/scale**2)*w_hat.pow(2).sum()/(n_tasks*t)\n",
        "            if abs(prev - loss.item()) < tol:\n",
        "                break\n",
        "            prev = loss.item()\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits_te = (xs_te @ w_hat).squeeze(-1).clamp(-4,4)\n",
        "            loss_te = loss_fn(logits_te, ys_te, r=r).mean().item()\n",
        "        all_losses.append(loss_te)\n",
        "    return all_losses\n",
        "\n",
        "# 4.3 True‑weights oracle\n",
        "def evaluate_oracle_true(xs_all, ys_all, ws, loss_type=\"poisson\", r=None):\n",
        "    n_tasks, n_points, _ = xs_all.shape\n",
        "    losses = []\n",
        "    for t in range(1, n_points):\n",
        "        x_te = xs_all[:, t:t+1, :]\n",
        "        y_te = ys_all[:, t:t+1]\n",
        "        logits = (x_te @ ws).squeeze(-1).clamp(-4,4)\n",
        "        if loss_type == \"poisson\":\n",
        "            loss = PoissonNLLLoss(log_input=True, full=True, reduction=\"none\")(logits, y_te)\n",
        "            losses.append(loss.mean().item())\n",
        "        else:\n",
        "            mu = torch.exp(logits)\n",
        "            r_t = torch.tensor(r, device=mu.device, dtype=mu.dtype)\n",
        "            probs = r_t/(r_t+mu)\n",
        "            dist = torch.distributions.NegativeBinomial(total_count=r_t, probs=probs)\n",
        "            losses.append(( -dist.log_prob(y_te) ).mean().item())\n",
        "    return losses\n",
        "\n",
        "# 4.4 Naive‑mean baseline\n",
        "def evaluate_naive(ys_all):\n",
        "    _, n_points = ys_all.shape\n",
        "    losses = []\n",
        "    fn = PoissonNLLLoss(log_input=False, full=True, reduction=\"none\")\n",
        "    for t in range(1, n_points):\n",
        "        y_tr = ys_all[:, :t]\n",
        "        y_te = ys_all[:, t:t+1]\n",
        "        pred = y_tr.mean(dim=1, keepdim=True)\n",
        "        loss = fn(pred, y_te).mean().item()\n",
        "        losses.append(loss)\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "44f7c7ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded checkpoint: /home/joseph_tennyson/.cache/huggingface/hub/models--icl-182--joint-training-r5.0/snapshots/60bf39e0e863e33e366b92aa47cbf6683ffbf3a9/model_2970.pt\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = os.path.join(ckpt_dir, ckpt_name)\n",
        "# state = torch.load(ckpt_path, map_location=device)\n",
        "print(\"Loaded checkpoint:\", ckpt_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sample Data & Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading state.pt\n",
            "Running transformer...\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, state))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning transformer...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m trans_losses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_val\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[25], line 8\u001b[0m, in \u001b[0;36mevaluate_transformer\u001b[0;34m(model, xs_all, ys_all, loss_type, r)\u001b[0m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m LOSS_REGISTRY[loss_type]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys_all\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m      9\u001b[0m     per_pos \u001b[38;5;241m=\u001b[39m loss_fn(out, ys_all, r\u001b[38;5;241m=\u001b[39mr)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m per_pos\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/182/in-context-learning-GLM/src/models.py:126\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, xs, ys, inds)\u001b[0m\n\u001b[1;32m    124\u001b[0m zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(xs, ys)\n\u001b[1;32m    125\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_in(zs)\n\u001b[0;32m--> 126\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    127\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_out(output)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction[:, ::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m][:, inds]\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:834\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte(input_ids)\n\u001b[0;32m--> 834\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/icl/lib/python3.8/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "xs_all, ys_all, ws_true = sample_data(\n",
        "    n_tasks,\n",
        "    n_train+1,\n",
        "    model_conf.n_dims,\n",
        "    scale=scale,\n",
        "    loss_type=loss_type,\n",
        "    r=r_val\n",
        ")\n",
        "xs_all, ys_all = xs_all.to(device), ys_all.to(device)\n",
        "\n",
        "from models import build_model\n",
        "\n",
        "ckpt_path = os.path.join(ckpt_dir, ckpt_name)\n",
        "state = torch.load(ckpt_path, map_location=device)\n",
        "model = build_model(model_conf).to(device)\n",
        "print(\"Loading\", ckpt_name)\n",
        "model.load_state_dict(state.get(\"model_state_dict\", state))\n",
        "\n",
        "print(\"Running transformer...\")\n",
        "trans_losses = evaluate_transformer(model, xs_all, ys_all, loss_type, r_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Baselines & GD‑Oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Running GD‑oracle…\")\n",
        "gd_losses    = evaluate_oracle_gd(\n",
        "    xs_all, ys_all, lr, max_steps, tol,\n",
        "    scale=scale, r=r_val, loss_type=loss_type\n",
        ")\n",
        "\n",
        "print(\"Running true‑weights oracle…\")\n",
        "true_losses  = evaluate_oracle_true(xs_all, ys_all, ws_true, loss_type, r_val)\n",
        "\n",
        "print(\"Running naive baseline…\")\n",
        "naive_losses = evaluate_naive(ys_all.cpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Plot All Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ctx = list(range(1, n_train+1))\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(ctx, trans_losses, label=\"Transformer\", linewidth=2)\n",
        "plt.plot(ctx, gd_losses,    label=\"GD Oracle\", linestyle=\"--\", linewidth=2)\n",
        "plt.plot(ctx, true_losses,  label=\"True‑weights\", linestyle=\":\", linewidth=2)\n",
        "plt.plot(ctx, naive_losses, label=\"Naive mean\", linestyle=\"-.\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Context length\")\n",
        "plt.ylabel(f\"{loss_type} NLL\")\n",
        "plt.title(f\"Loss vs. Context length (type={loss_type})\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "icl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
